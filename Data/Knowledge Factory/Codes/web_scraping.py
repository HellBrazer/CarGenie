# -*- coding: utf-8 -*-
"""Web scraping.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/129kvt98SUkU8g56SLc9SHWC1IYqs2cm-
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

pd.set_option("display.max_columns", None)
pd.set_option("display.max_rows", 100)

import time



# Base URL for the website
main_url = 'https://www.carwale.com'

# Send a GET request to the landing page (brands page)
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def fetch_page_content(url, headers):
    """Fetches the webpage content for a given URL."""
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Raise HTTPError for bad responses
        return BeautifulSoup(response.text, 'lxml')
    except requests.RequestException as e:
        print(f"Error fetching page {url}: {e}")
        return None

def scrape_brands():
    """Scrapes brand names and URLs from the main page."""
    brand_list = []

    bs_object = fetch_page_content(main_url, headers)
    if not bs_object:
        return brand_list

    try:
        # Find the section containing the brands
        brands_section = bs_object.find(string='View More Brands').parent.parent
        brands = brands_section.find_all('li')

        # Enumerate over the brands and print them out with their URLs
        for i, brand in enumerate(brands):
            brand_name = brand.text.strip()  # Clean up brand name
            brand_url = main_url + brand.a['href']  # Construct full URL for brand page
            brand_list.append((brand_name, brand_url))  # Store brand name and URL
    except AttributeError:
        print("Could not find the brands section.")

    return brand_list

def scrape_models(brand_name, brand_url):
    """Scrapes model names and URLs for a given brand."""
    brand_soup = fetch_page_content(brand_url, headers)
    if not brand_soup:
        return []

    models_list = []

    try:
        models = brand_soup.find_all('a', class_='o-cpnuEd o-SoIQT o-cJrNdO o-fzpilz')
        for model in models:
            model_name = model.find('h3', class_='o-jjpuv o-cVMLxW o-mHabQ o-fzpibK').text.strip()
            model_url = main_url + model['href']
            models_list.append((model_name, model_url))
    except AttributeError:
        print("Could not find models on the page.")

    return models_list

def scrape_variants(model_name, model_url):
    """Scrapes variant names and details for a given model."""
    model_soup = fetch_page_content(model_url, headers)
    if not model_soup:
        return []

    variants_list = []

    try:
        # Extract variants and their details
        variants = model_soup.find_all('tr', class_='o-dJmcbh version-table__tbody-tr')

        for variant in variants:
            variant_name = variant.find('div', class_='o-fzpilz').a.text.strip()
            variant_url = main_url + variant.find('a')['href']  # Construct variant URL
            variant_specs = scrape_specifications(variant_url)

            # Add variant data along with its specifications
            variants_list.append({
                'model_name': model_name,
                'variant_name': variant_name,
                'variant_url': variant_url,
                **variant_specs  # Merges the specifications as columns
            })

            time.sleep(2)  # Sleep between requests to prevent overloading the server
    except AttributeError:
        print("Could not extract variant information.")

    return variants_list

def scrape_specifications(variant_url):
    """Scrapes specifications from the variant page."""
    variant_soup = fetch_page_content(variant_url, headers)
    if not variant_soup:
        return {}

    specs_dict = {}

    # Find all the specification sections
    specs_sections = variant_soup.find_all('div', class_='o-dsiSgT o-eemiLE o-cYdrZi o-AxgTO o-cpnuEd o-eFudgX o-eCFISO o-ItVGT o-bQNYa-D o-biKUts o-eUqSLf o-cpnuEd')

    for spec in specs_sections:
        try:
            # Get the specification name (e.g., 'Engine', 'Fuel Type')
            spec_name = spec.find('div', class_='o-zmksK o-fHmpzP').text.strip()

            # Get the specification value (e.g., '3 Cylinders', 'Petrol')
            spec_value = spec.find('div', class_='o-cJrNdO o-fzpimw o-ckGLSv o-fzpibK o-cMwvCl o-emwzWU').text.strip()

            # Add to the specs dictionary
            specs_dict[spec_name] = spec_value
        except AttributeError:
            # In case an expected tag is not found, skip this spec
            continue

    return specs_dict



# Initialize an empty list to store all the data
data = []

# Fetch and scrape the brands
brands = scrape_brands()

# For demonstration, limit to the first brand
for brand_name, brand_url in brands:
    # Scrape models for the brand
    models = scrape_models(brand_name, brand_url)

    # Limit to the first model for demonstration
    for model_name, model_url in models:
        # Scrape variants for the model
        variants_data = scrape_variants(model_name, model_url)

        # Append scraped data to the list
        for variant in variants_data:
            data.append({
                'brand_name': brand_name,
                'model_name': variant['model_name'],
                'variant_name': variant['variant_name'],
                'variant_url': variant['variant_url'],
                **{k: v for k, v in variant.items() if k not in ['model_name', 'variant_name', 'variant_url']}
            })

df = pd.DataFrame(data)





df.head()



df.to_csv("Carwale_scraped_data.csv", index = False)

